---
title: 知识点汇总3
tags:
  - null
categories:
  - null
date: 2020-05-31 14:03:50
---

70. ioc原理、aop原理和应用

    1. ioc原理 控制反转（依赖注入）
       1. 本质是，spring维护了一个实例的容器，在需要使用某个实例的地方，自动注入这个实例
       2. 主要运用了反射机制，通过反射来创建约定的实例，并维护在容器中
       
    2. aop原理 面向切面编程
      
       [AOP原理](https://juejin.im/post/5bf4fc84f265da611b57f906)
       
       1. 原理是动态代理。代理模式的定义：给某一个对象提供一个代理，并由代理对象控制对原对象的引用。实现方式：
       
          1. 首先有接口A，类a实现接口A
       
          2. 接着创建一个bInvocationHandler类，实现InvocationHandler接口，持有一个被代理对象的实例target，invoke方法中触发method
       
             ```java
                 /**
                  * proxy: 代表动态代理对象，编译时候生成的
                  * method：代表正在执行的方法
                  * args：代表调用目标方法时传入的实参
                  */
                 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                     System.out.println("代理执行" +method.getName() + "方法");
                     Object result = method.invoke(target, args);
                     return result;
                 }
             ```
       
          3. 创建代理对象
       
             ```
             A a = (A) Proxy.newProxyInstance(A.class.getClassLoader(), new Class<?>[]{A.class}, handler)
             ```
       
             ![image-20200601110636533](/github/northernw.github.io/image/image-20200601110636533.png)
       
       2. 比如日志、监控等公共行为可以通过AOP来实现，避免大量重复代码
       
       3. 元素
       
          1. 切面：拦截器类，定义切点以及通知
          2. 切点：具体拦截的某个业务点
          3. 通知：切面当中的方法，声明通知方法在目标业务层的执行位置，通知类型如下：
             1. 前置通知：@Before 在目标业务方法执行之前执行
             2. 后置通知：@After 在目标业务方法执行之后执行
             3. 返回通知：@AfterReturning 在目标业务方法返回结果之后执行
             4. 异常通知：@AfterThrowing 在目标业务方法抛出异常之后
             5. 环绕通知：@Around 功能强大，可代替以上四种通知，还可以控制目标业务方法是否执行以及何时执行
       
       4. aspectj切面扫描的细节再看下

65. ~~大数据相关，MapReduce~~ 不考虑

66. Docker的原理【待看】

    [Docker核心技术与实现原理](http://www.dockone.io/article/2941)

    [Docker底层原理介绍](https://www.jianshu.com/p/e1f7b8d5184c)

67. Http协议

    1. 基础概念

       1. URI：uniform resource identifier 统一资源标识符

          1. URL：uniform resource locator 统一资源定位符
          2. URN：uniform resource name 统一资源名称
          3. URI包括URL和URN

       2. 请求报文的格式

          1. request line 请求行：请求方法，URL，协议

          2. request headers 请求头：各种header

          3. 请求行和请求头合称为**请求消息头**

          4. 空行分隔开请求头和请求消息体

          5. request message body **请求消息体**：key-value形式或者raw格式等等

             ![image-20200531143718430](/github/northernw.github.io/image/image-20200531143718430.png)

       3. 响应报文的格式

          1. status line 状态行：协议，状态码

          2. response headers 响应头

          3. 状态行和响应头合称为响应消息头

          4. 空行分隔开消息头和消息体

          5. response message body 响应消息体

             ![image-20200531143732598](/github/northernw.github.io/image/image-20200531143732598.png)

    2. HTTP方法

       1. get 主要用来获取资源
       2. head 获取报文首部，主要用于确认 URL 的有效性以及资源更新的日期时间等。
       3. post 主要用来传输数据
       4. put 上传文件，不带验证机制存在安全问题，一般不使用
       5. patch 对资源进行部分修改 -- 也不常用
       6. delete 删除文件，与put功能相反，同样不带验证机制
       7. options 查询支持的方法，会返回`Allow: GET, POST, HEAD, OPTIONS`这样的内容
       8. connect 要求在与代理服务器通信时建立隧道。使用 SSL(Secure Sockets Layer，安全套接层)和 TLS(Transport Layer Security，传输层安全)协议把通信内容 加密后经网络隧道传输。
       9. trace 追踪路径，一般也不用...

    3. HTTP状态码

       简要记一下

       1. 1XX 信息性状态码，接收的请求正在处理
       2. 2XX 请求正常处理完毕
       3. 3XX 重定向
       4. 4XX 客户端错误
       5. 5XX 服务端错误

    4. 再关注下前面的http和HTTPS的比较

       

68. cookie session介绍一下

    1. cookie

       1. 是服务器发送到用户浏览器并保持在本地的一小块数据，会在浏览器向同一服务器再次发起请求时被带上。
       2. 用途：
          1. 会话状态管理（比如用户登录状态、购物车等）
          2. 个性化设置（比如用户自定义设置、主题等）
          3. 浏览器行为分析
       3. 生成方式
          1. 服务器发送`Set-Cookie: yummy_cookie=choco`这样的header，客户端得到响应报文后把cookie存在浏览器
          2. 浏览器通过`document.cookie`属性可创建新的cookie
       4. HttpOnly 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。
       5. Secure 标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信 息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。

    2. session

       1. 存储在服务端，可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中
       2. 使用 Session 维护用户登录状态的过程如下:
          1. 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中; 
          2. 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID; 
          3. 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中;
          4. 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取 出用户信息，继续之前的业务操作。

    3. cookie和session的选择

       1. cookie只能存储ASCII码字符串，session可以存储任何类型的数据

       2. cookie存储在浏览器中，安全性较低

       3. 对于大型网址，如果所有用户信息都存储在session中，开销比较大 -- 【感觉不是个问题...】

          

69. session表结构怎么设计，储存在哪里？

    1. 我们项目里没有直接使用session，用的是商城统一单点登录
    2. 
    3. 如果我设计
       1. 首先一个用户请求过来，如果没有带session id，先重定向到登录页
       2. 收到登录请求，身份验证通过后，生成一个session，key为唯一ID，即session id，value为需要存储的信息，比如用户名、生成时间等，将session id作为cookie响应发回浏览器
       3. 众多的session是key-value结构，session本身也是key-value结构
       4. 存储在Redis

70. 你们的session cookie在项目里运用到哪里？

    1. session是SSO用的，cookie也主要是SSO用的
    2. 偶尔用的cookie是虚拟登录这样的场景
       1. 比如超级账号：员工的erp账号以只读的形式登录到用户账号，主要用于排查问题
       2. 比如账号管家：系统中，账号体系中的主账号可以登录到子账号上，一般也只读
       3. 再如虚拟登录，业务范畴上，两个账号建立授权关系，B账号可以虚拟登录到A账号上，代为操作系统
       4. 实现：被登录人一般是sso中的session对应的用户，属于资源所属者；操作者是erp账号、主账号、虚拟登录账号等，会有登录类型区分，这些信息会先加密，再存入cookie中（还会有不同的拦截器，进行身份和权限验证）

77. 单点登录的实现

    1. CAS

       TGT：Ticket Granted Ticket（俗称大令牌，或者说票根，他可以签发ST）。【类似session】

       TGC：Ticket Granted Cookie（cookie中的value），存在Cookie中，根据他可以找到TGT。【类似session id】

       ST：Service Ticket （小令牌），是TGT生成的，默认是用一次就生效了。也就是上面的ticket值。

       ps: 未登录状态下，访问app1时，展示登录页，浏览器会写入cas服务器的TGC；第二次访问app2，（因为app2本身校验当前请求未登录）重定向到cas服务器时，会带上TGC，cas服务器根据TGC判断用户已登录，签发新的ST再重定向到app2，这时候app2用ST校验通过，记录下自己的session cookie，提供请求内容。

       ![img](/github/northernw.github.io/image/167772fc86501755.png)

    2. ~~OAuth~~ 【不看了不看了！】

       https://juejin.im/post/5cc81d5451882524f72cd32c

       https://juejin.im/post/5b3b3b61f265da0f955ca780

       <img src="/github/northernw.github.io/image/image-20200601201126291.png" alt="image-20200601201126291" style="zoom:50%;" />

       <img src="/github/northernw.github.io/image/image-20200601201230467.png" alt="image-20200601201230467" style="zoom:50%;" />
       
       

78. 算法题：[删除链表中重复的节点]在一个排序的链表中,存在重复的节点,请删除该链表中重复的节点,重复的节点不保留,返回链表头指针.例如,链表1-2-3-3-4-4-5处理后为1-2-5

    

79. TCP/UDP的区别介绍一下

    1. UDP：用户数据报协议 UDP(User Datagram Protocol)是无连接的，尽最大可能交付，没有拥塞控制，面向报文 (对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部)，支持一对一、一对多、多对一和多对多 的交互通信。

    2. TCP：传输控制协议 TCP(Transmission Control Protocol)是面向连接的，提供可靠交付，有流量控制，拥塞控 制，提供全双工通信，面向字节流(把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据 块)，每一条 TCP 连接只能是点对点的(一对一)。

    3. UDP首部格式

       首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。

       <img src="/github/northernw.github.io/image/image-20200602195522814.png" alt="image-20200602195522814" style="zoom:50%;" />

    4. TCP首部格式

       <img src="/github/northernw.github.io/image/image-20200602195629503.png" alt="image-20200602195629503" style="zoom:50%;" />

       1. 序号 :用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。

       2. 确认号 :期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据 长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。

       3.  数据偏移 :指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。

       4. 确认 ACK :当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。

       5. 同步 SYN :在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建 立连接，则响应报文中 SYN=1，ACK=1。

       6. 终止 FIN :用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 

       7. 窗口 :窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空 间是有限的。

          

80. TCP如何保证传输的有效性。

    使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。

    

81. TCP滑动窗口

    1. 暂时存放字节流。发送方和接收方各有一个窗口，接收方通过TCP报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其他信息设置自己的窗口大小。

    2. 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态;接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

    3. 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前 的所有字节都已经被接收。

       ![image-20200602202005619](/github/northernw.github.io/image/image-20200602202005619.png)

    

82. TCP的拥塞控制

    1. 与**流量控制**的区别：

       1. 流量控制是上一题里窗口，接收方发送窗口值来控制发送方的窗口大小，从而影响发送方的发送速率。将窗口值设置为0，则发送方不能发送数据。
        2. 控制发送方的发送速率，保证接收方来得及接收。

    2. **拥塞控制**

       1. 是为了降低整个网络的拥塞程度

       2. 主要通过四个算法进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。

       3. 发送方需要维护一个叫做拥塞窗口(cwnd)的状态变量（只是一个状态变量，不是发送方窗口。再区别一下，拥塞窗口讨论的是报文段数量，发送窗口讨论的是字节数量）

       4. **慢开始与拥塞避免**

          1. 发送的最初是慢开始，cwnd=1，发送方只能发送一个报文段；接收到确认后，将cwnd加倍，之后能发送的报文段数量是2、4、8..

          2. ssthresh是慢开始门限（初始值自己定），当cwnd >= ssthresh 时，进入拥塞避免，每个轮 次只将 cwnd 加 1。

          3. 如果出现超时，则另ssthresh = cwnd / 2，并重新执行慢开始。

          4. 见图1、2、3

             ![image-20200602203232342](/github/northernw.github.io/image/image-20200602203232342.png)

       5. 快重传与快恢复

          1. 【在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。】

          2. 在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。【例如收到三个 M2，则 M3 丢失，立即重传 M3。】

          3. 同时执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，并直接进入拥塞避免。

          4. 见上图4、5

             ![image-20200602203554747](/github/northernw.github.io/image/image-20200602203554747.png)

             

83. TCP建立连接的三次握手

    假设A为客户端，B为服务端

    1. 首先B处于监听（listen）状态，等待客户的连接请求
    2. A向B发送**连接（SYN，同步）请求报文**，SYN=1，ACK=0，seq=x（选择一个初始的序号x）
    3. B收到连接请求报文，如果同意建立连接，则向A发送**连接确认报文**，SYN=1，ACK=1，ack=x+1（确认号为x+1），seq=y（同时也选择一个初始的序号y）
    4. A收到B的连接确认报文后，还要向B发出确认，seq=x+1（序号为x+1），ack=y+1（确认号为y+1）

    为什么要三次握手？

    三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

    客户端发送的连接请求如果在网络中滞留，那么隔很长时间才能收到服务器发回的连接确认，在这段时间内，客户端等待一个超时重传时间后，就会重新发送连接请求。同时滞留的连接请求最后还是会到达服务器，如果只是两次握手，那么服务器会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

    ![image-20200603103804834](/github/northernw.github.io/image/image-20200603103804834.png)

84. TCP四次挥手断开连接

    ack都为1.

    1. A 发送连接释放报文，FIN=1。

    2. B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 

    3. 当 B 不再需要连接时，发送连接释放报文，FIN=1。

    4. A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL(最大报文存活时间)后释放连接。

    5. B 收到 A 的确认后释放连接。

    **四次挥手的原因**

    客户端发送FIN连接释放报文后，服务器收到这个报文就进入**CLOSE_WAIT**状态，这个状态是为了让服务器端发送未传送完毕的数据，发完后服务器就会发送FIN连接释放报文。  

     **TIME_WAIT**

    客户端收到服务端的FIN报文后进入此状态，并不是直接进入CLOSED状态，还需要等待一个时间计时器设置的时间2MSL。有两个理由：

    1. 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文， A 等待一段时间就是为了处理这种情况的发生。
    2. 等待一段时间是为了让本次连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

    ![image-20200603124530763](/github/northernw.github.io/image/image-20200603124530763.png)

    

85. Java的锁机制

    [Java锁机制](https://juejin.im/post/5e0c5eba6fb9a047ef326a0b)  [AQS机制](https://juejin.im/post/5e16effef265da3e491a3f5e)

    1. 背景知识

       1. 指令流水线：现代处理器的体系结构中，采用流水线的方式对指令进行处理。每个指令的工作可分为5个阶段：取指令、指令译码、执行指令、访存取数和结果写回。
       2. CPU多级缓存：计算机系统中，存在CPU高速缓存，用于减少处理器访问内存所需平均时间。当处理器发出内存访问请求时，会先查看缓存中是否有请求数据，若命中则直接返回该数据；若不存在，则先从内存中将数据载入缓存，再将其返回处理器。

    2. 问题引入

       1. 原子性：即一个操作或者多个操作 要么全部执行**并且执行的过程不会被任何因素打断**，要么就都不执行。（比如i++，如果对实例变量i的操作不做额外的控制，那么多个线程同时调用，就会出现覆盖现象，丢失部分更新。） -- 因为指令流水线
       2. **可见性**：是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值（存在可见性问题的根本原因是由于缓存的存在）-- 因为存在缓存
       3. **顺序性**：即程序执行的顺序按照代码的先后顺序执行 -- 因为存在指令重排

    3. JMM内存模型

       主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。这里的变量指共享变量（存在竞争问题的变量），如实例字段、静态字段、数组对象元素等。不包括线程私有的局部变量、方法参数等。

       1. 内存划分：分为主内存和工作内存，【每个线程都有自己的工作内存，它们共享主内存。】【线程对共享变量的所有读写操作都在自己的工作内存中进行，不能直接读写主内存中的变量。】【不同线程间也无法直接访问对方工作内存中的变量，线程间变量值的传递必须通过主内存完成。】
          - 主内存（Main Memory）存储所有共享变量的值。

          - 工作内存（Working Memory）存储该线程使用到的共享变量在主内存的的值的副本拷贝。

       2. 内存间交互规则【一个变量如何从主内存拷贝到工作内存，如何从工作内存同步到主内存中】

          ![image-20200603190808840](/github/northernw.github.io/image/image-20200603190808840.png)

          **8种原子操作**

          - lock: 将一个变量标识为被一个线程独占状态
          - unclock: 将一个变量从独占状态释放出来，释放后的变量才可以被其他线程锁定
          - read: 将一个变量的值从主内存传输到工作内存中，以便随后的load操作
          - load: 把read操作从主内存中得到的变量值放入工作内存的变量的副本中
          - use: 把工作内存中的一个变量的值传给执行引擎，每当虚拟机遇到一个使用到变量的指令时都会使用该指令
          - assign: 把一个从执行引擎接收到的值赋给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时，都要使用该操作
          - store: 把工作内存中的一个变量的值传递给主内存，以便随后的write操作
          - write: 把store操作从工作内存中得到的变量的值写到主内存中的变量

          **原子操作的使用规则**

          - read、load、use必须成对顺序出现，但不要求连续出现。assign、store、write同之；

          - 变量诞生和初始化：变量只能从主内存“诞生”，且须先初始化后才能使用，即在use/store前须先load/assign；

          - lock一个变量后会清空工作内存中该变量的值，使用前须先初始化；unlock前须将变量同步回主内存；

          - 一个变量同一时刻只能被一线程lock，lock几次就须unlock几次；未被lock的变量不允许被执行unlock，一个线程不能去unlock其他线程lock的变量。

          对于double和long，虽然内存模型允许对非volatile修饰的64位数据的读写操作分为两次32位操作来进行，但商用虚拟机几乎把64位数据的读写实现为了原子操作，可以忽略这个问题。

       3. 先行发生原则

          【Java内存模型具备一些先天的“有序性”，即不需要通过任何同步手段（volatile、synchronized等）就能够得到保证的有序性，这个通常也称为happens-before原则。】

          如果两个操作的执行次序不符合先行原则且无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。

          1. 程序次序规则（Program Order Rule）：一个线程内，逻辑上书写在前面的操作先行发生于书写在后面的操作。
          2. 监视器锁规则（Monitor Lock Rule）：一个unLock操作先行发生于后面对同一个锁的lock操作。“后面”指时间上的先后顺序。
          3. **volatile变量规则**（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作。“后面”指时间上的先后顺序。
          4. 传递规则（Transitivity）：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。
          5. 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每个一个动作。
          6. 线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生（通过Thread.interrupted()检测）。
          7. 线程终止规则（Thread Termination Rule）：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行。
          8. 对象终结规则（Finaizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于他的finalize()方法的开始。

    4. 问题解决

       1. 原子性

          1. 由JMM保证的原子性变量操作
          2. 基本数据类型的读写（工作内存）是原子的
          3. JMM的lock和unlock指令可以实现更大范围的原子性保证，虚拟机提供synchronized关键字和Lock锁来保证原子性。

       2. 可见性

          1. **volatile关键字**修饰的变量，被线程修改后会立即同步回主内存，其他线程要读取这个变量会从主内存刷新值到工作内存。（因为缓存一致性协议会让其他工作内存中的该变量拷贝无效，必须得从主内存再读取）即read、load、use三者连续顺序执行，assign、store、write连续顺序执行。
       
       2. **synchronized/Lock** ~~由lock和unlock的使用规则保证【这里有疑问啊，synchronized有lock和unlock，但是Lock没有吧...Lock怎么保证可见性？还是说Lock保证不了可见性。可见性只能由volatile保证？--参见ConcurrentHashMap，有synchronized，还配合volatile使用---ConcurrentHashMap有些是不加锁的操作，比如get，所以还是用volatile保证可见性。synchronized 锁的是某个node节点，对这个node节点的】~~
       
          1. synchronized有语义规定，说是通过内存屏障实现的
       
                线程解锁前，必须把共享变量的最新之刷新到主内存中
                线程加锁前，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值
       
             2. Lock用了cas，有`lock cmpxchg`，lock前缀指令保证了可见性，同时有内存屏障的作用
       
             **同时，这俩还能保证临界区操作的所有变量的可见性**因为内存屏障
       
             > LOCK前缀的指令具有如下效果：
             >
             > - 把写缓冲区中所有的数据刷新到内存中
             >
             > 注意，是所有的数据，可不仅仅是对state的修改
       
             > [ReentrantLock对可见性的支持](https://www.zhihu.com/question/41016480/answer/130906913)
             >
             > All threads will see the most recent write to a volatile field, along with any writes which preceded that volatile read/write. Reentrantlock的lock和unlock方法实际上会cas一个state的变量，state是volatile的，因此夹在两次state之间的操作都能保证可见性。这应该算是happen before的传递性...
       
       3. 顺序性
       
          1. volatile 禁止指令重排序
          2. synchronized/Lock “一个变量在同一个时刻只允许一条线程对其执行lock操作” -- 感觉这个也没用，不然双重检查的单例怎么还用volatile关键字来防止重排序 -- 最多保证原子性，被加锁内容按照顺序被多个线程执行
       
    5. 锁机制

       1. volatile：
       
          保证可见性和顺序性【实现方式：内存屏障？缓存一致性协议？】
       
          1. volatile修饰的变量，在进行写操作的时候会多一行汇编代码，lock指令，做两件事：
             1. 将当前处理器缓存行的数据写回系统内存
             2. 使其他处理器里缓存了该内存地址的数据无效。【实现缓存一致性协议，处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了（处理器发现自己缓存行对应的内存地址被修改，就会将自己的缓存设置成无效状态）】
       
       2. final：有两个重排序规则 -- 不甚了解
          1. **写final域的重排序规则**：在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。
          2. 读final域的重排序规则：初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。
       
       3. synchronized关键字
          1. 使用哪个对象的监视器：
             - 修饰对象方法时，使用当前对象的监视器
             - 修饰静态方法时，使用类类型（Class 的对象）监视器
             - 修饰代码块时，使用括号中的对象的监视器
               - 必须为 Object 类或其子类的对象
             
          2. 无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁
            
             简单理解，只有一个线程CAS时，如果CAS成功，表示没有锁竞争，保持偏向锁状态，如果CAS失败，说明有竞争，（先撤销偏向锁，将对象头设置成无锁状态，并设置为不可偏向）升级为轻量级锁。
             
             
             
             1. 偏向锁：当锁对象第一次被线程获取的时候，虚拟机会将对象头中的标志位设为01，可偏向。同时使用**CAS操作把获取到到这个锁的线程的ID记录上对象的Mark Word中**。如果CAS操作成功，持有偏向锁的这个线程后续进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作。
             2. 轻量级锁：如果不止一个线程尝试获取锁，就会升级到轻量级锁。**通过自适应自旋CAS的方式获取锁。**如果获取失败，说明存在竞争，膨胀为重量级锁，线程阻塞。**将对象头中的Mark Word复制到栈帧（一块空间，称为锁记录）中，然后用CAS将对象头中的Mark Word替换为指向栈帧中锁记录的指针。**
             3. 重量级锁：通过系统的线程互斥锁来实现的，未获取到锁的线程会阻塞挂起
       
       4. AQS

86. 【内存屏障和"lock"前缀指令】理解

    volatile通过编译器，既会增加"lock"前缀指令，也会加上内存屏障（mfence等）

    内存屏障是抽象概念，各个硬件、处理器实现不同

    lock前缀指令和mfence等是具体实现

    mesi协议保证缓存和主存间的一致性

    > 有了msei协议，为什么汇编层面还需要lock(volatile)来实现可见性？ - Rob Zhang的回答 - 知乎 https://www.zhihu.com/question/334662600/answer/747038084
    >
    > 内存屏障能保证从storebuffer到缓存再到主存的一致性，在多线程运行中可以作为mesi的补充（因为mesi管不到那么多），但内存屏障
    >
    > **lock前缀主要是为了提供原子操作，虽然它也包含了内存屏障功能**（强制将寄存器、缓存（、storebuffer/invalid queue或类似的东西）等强制同步到主存）

    

    > 关于内存屏障的几个问题？ - cao的回答 - 知乎 https://www.zhihu.com/question/47990356/answer/108650501
    >
    > x86在Windows下的内存屏障是用lock前缀指令来达到效果的

    

    **简单理解：**

    **内存屏障保证了寄存器和缓存之间的一致性**

    **lock前缀保证操作原子性**

    **二者都能保证可见性**

    

    x86架构的内存屏障

    1. sfence: Store Barrier = StoreStore Barriers 写屏障

       所有sfence之前的store指令都在sfence之前被执行，并刷出到CPU的L1 Cache中；

       所有在sfence之后的store指令都在sfence之后执行，禁止重排序到sfence之前。

       所以，所有Store Barrier之前发生的内存更新都是可见的。

    2. lfence: Load Barrier = LoadLoad Barriers 读屏障

       所有在lfence之后的load指令，都在lfence之后执行，并且一直等到load buffer被该CPU读完才能执行之后的load指令（即要刷新失效的缓存）。配合sfence，使所有sfence之前发生的内存更新，对lfence之后的load操作都可见。

    3. mfence: Full Barrier = StoreLoad Barriers 全屏障

       综合了sfence和lfence的作用，强制所有在mfence之前的store/load指令都在mfence之前被执行，之后的store/load指令都在之后执行，禁止跨越mfence重排序。并且都刷新到缓存&重新载入无效缓存。

       

87. 3种重排序类型

    1是编译器重排序，2和3是处理器重排序。会导致多线程程序出现内存可见性问题。

    1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

    2. 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

    3. 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

       

88. 死锁

    死锁定义：多个进程循环等待它方占有的资源而无限期地僵持下去的局面。

    产生死锁的必要条件：

    1. 互斥（mutualexclusion），一个资源每次只能被一个进程使用
    2. 不可抢占（nopreemption），进程已获得的资源，在未使用完之前，不能强行剥夺
    3. 占有并等待（hold andwait），一个进程因请求资源而阻塞时，对已获得的资源保持不放
    4. 环形等待（circularwait），若干进程之间形成一种首尾相接的循环等待资源关系。

    对待死锁的策略主要有：

    1. 死锁预防：破坏导致死锁必要条件中的任意一个就可以预防死锁。例如，要求用户申请资源时一次性申请所需要的全部资源，这就破坏了保持和等待条件；将资源分层，得到上一层资源后，才能够申请下一层资源，它破坏了环路等待条件。预防通常会降低系统的效率。

    2. 死锁避免：避免是指进程在每次申请资源时判断这些操作是否安全，例如，使用银行家算法。死锁避免算法的执行会增加系统的开销。

    3. 死锁检测：死锁预防和避免都是事前措施，而死锁的检测则是判断系统是否处于死锁状态，如果是，则执行死锁解除策略。

    4. 死锁解除：这是与死锁检测结合使用的，它使用的方式就是剥夺。即将某进程所拥有的资源强行收回，分配给其他的进程。

       

89. 避免死锁的几个常见方法

    1. 避免一个线程同时获取多个锁

    2. 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。

    3. 尝试使用定时锁，使用`lock.tryLock(timeout)`来代替使用内部锁机制。

    4. 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

       

90. ~~三次握手和四次挥手,time_wait是什么状态~~【见83、84】

91. ~~B树 B+树区别说一下~~

    B树非叶子节点也存储数据

92. ~~数据库平时用到过什么 咱们先问MySQL MySQL索引原理知道吗，问了两种索引的区别~~

93. ~~索引的分类和优缺点~~

94. ~~innodb和myisam的区别~~

95. ~~乐观锁悲观锁区别说一下~~

96. ~~数据库四种隔离状态 分别有什么问题~~

    

97. redis的数据结构

    [Redis基础](https://juejin.im/post/5db66ed9e51d452a2f15d833)

    Redis 键值（Key-Value）存储数据库

    1. string 字符类型
    2. map 散列类型
    3. list 列表类型
    4. set 集合类型
    5. sortedset 有序集合类型

98. sortset底层，原理，怎么保证有序

    

99. 冯诺依曼计算机的结构

100. 操作系统的虚拟内存

101. 进程的调度

102. 进程间的通讯方式

103. 线程间的同步方式

104. 进程和线程的区别

105. 常见的排序算法

106. spring 事务实现

107. spring的循环依赖如何解决？为什么要三级缓存？

108. jvm参数调优详细过程，到为什么这么设置，好处，一些gc场景，如何去分析gc日志

109. 优先级队列的底层原理？

110. redis如何实现分布式锁，zk如何实现分布式锁，两者的区别。如果service还没执行完，分布式锁在redis中已经过期了，怎么解决这种问题

111. synchronized底层实现，加在方法上和加在同步代码块中编译后的区别、类锁、对象锁

112. mvcc，怎么实现rr rc

113. mysql间隙锁有没有了解，死锁有没有了解，写一段会造成死锁的sql语句，死锁发生了如何解决，mysql有没有提供什么机制去解决死锁

114. 如何保证RocketMQ 消息的顺序性，如何解决重复消费问题

115. explain 可以看到哪些信息，什么信息说明什么，explain的结果列讲一下

116. aqs，countDownLatch如何实现

117. java如何实现序列化的，Serialization底层如何实现的

118. 线上服务器cpu飙高，如何处理这个问题

119. 内核态 和 用户态、cas 和 sout 哪个用到了内核态和用户态的切换

120. 哪些典型的应用用的是udp

121. 计算密集型/IO密集型 任务 分别如何设置线程池的核心线程数和最大线程数，为什么这么设置

122. synchronized底层实现

     https://juejin.im/post/5bfe6ddee51d45491b0163eb

123. redis实现 带注解3.0源码

     《Redis设计与实现》

     https://github.com/huangz1990/redis-3.0-annotated

     ​    

## 扩展信息备查
1. http status备查

    1XX 信息
     100 Continue :表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。

    2XX 成功

    200 OK
     204 No Content :请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端 往服务器发送信息，而不需要返回数据时使用。
     206 Partial Content :表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。

    3XX 重定向

    301 Moved Permanently :永久性重定向
     302 Found :临时性重定向
     303 See Other :和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。
     注:虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都 会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。
     304 Not Modified :如果请求报文首部包含一些条件，例如:If-Match，If-Modified-Since，If-None- Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。
     307 Temporary Redirect :临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。

    4XX 客户端错误

    400 Bad Request :请求报文中存在语法错误。
     401 Unauthorized :该状态码表示发送的请求需要有认证信息(BASIC 认证、DIGEST 认证)。如果之前已进 行过一次请求，则表示用户认证失败。
     403 Forbidden :请求被拒绝。
     404 Not Found

    5XX 服务器错误
     500 Internal Server Error :服务器正在执行请求时发生错误。

    503 Service Unavailable :服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。